<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<parent>
		<groupId>org.springframework.boot</groupId>
		<artifactId>spring-boot-starter-parent</artifactId>
		<version>2.2.2.RELEASE</version>
		<relativePath/> <!-- lookup parent from repository -->
	</parent>
	<groupId>com.main</groupId>
	<artifactId>hybrid-db</artifactId>
	<version>0.0.1-SNAPSHOT</version>
	<packaging>war</packaging>
	<name>hybrid-db</name>
	<description>Hybrid DB</description>

	<properties>
		<java.version>1.8</java.version>
	</properties>

	<dependencies>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-data-elasticsearch</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka-streams</artifactId>
		</dependency>
		<dependency>
			<groupId>org.springframework.kafka</groupId>
			<artifactId>spring-kafka</artifactId>
		</dependency>

		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-tomcat</artifactId>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-test</artifactId>
			<scope>test</scope>
			<exclusions>
				<exclusion>
					<groupId>org.junit.vintage</groupId>
					<artifactId>junit-vintage-engine</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.springframework.kafka</groupId>
			<artifactId>spring-kafka-test</artifactId>
			<scope>test</scope>
		</dependency>

		<dependency>
			<groupId> org.apache.cassandra</groupId>
			<artifactId>cassandra-all</artifactId>
			<version>0.8.1</version>

			<exclusions>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-log4j12</artifactId>
				</exclusion>
				<exclusion>
					<groupId>log4j</groupId>
					<artifactId>log4j</artifactId>
				</exclusion>
			</exclusions>
		</dependency>

		<!--SPARK -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_2.11</artifactId>
			<version>2.4.5</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_2.11</artifactId>
			<version>2.4.5</version>
		</dependency>
<!--
SparkSession create
java.lang.ClassNotFoundException: com.google.common.cache.CacheBuilder-->
		<dependency>
			<groupId>com.google.guava</groupId>
			<artifactId>guava</artifactId>
			<version>29.0-jre</version>
		</dependency>
<!--		read csv java.lang.NoSuchMethodError: scala.Product.$init$(Lscala/Product;)V-->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>2.11.12</version>
		</dependency>
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-reflect</artifactId>
			<version>2.11.12</version>
		</dependency>
<!--
work with RDD
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapred.FileInputFormat-->
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>3.2.1</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-mapreduce-client-core</artifactId>
			<version>3.2.1</version>
		</dependency>
		<dependency>
			<groupId>commons-io</groupId>
			<artifactId>commons-io</artifactId>
			<version>2.6</version>
		</dependency>
		<!--
        df.show
        java.lang.ClassNotFoundException: org.codehaus.janino.InternalCompilerException-->
		<dependency>
			<groupId>org.codehaus.janino</groupId>
			<artifactId>commons-compiler</artifactId>
			<version>3.0.15</version>
		</dependency>



		<!--
        df.show()
        java.lang.ClassNotFoundException: org.codehaus.janino.InternalCompilerException
        -->

<!--		<dependency>-->
<!--			<groupId>org.codehaus.janino</groupId>-->
<!--			<artifactId>janino</artifactId>-->
<!--			<version>3.1.0</version>-->
<!--		</dependency>-->





		<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-core_2.11</artifactId>-->
<!--			<version>2.0.0</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-sql_2.11</artifactId>-->
<!--			<version>2.0.0</version>-->
<!--		</dependency>-->


<!--		<dependency>-->
<!--			<groupId>org.scala-lang</groupId>-->
<!--			<artifactId>scala-library</artifactId>-->
<!--			<version>2.11.8</version>-->
<!--		</dependency>-->
		<dependency>
			<groupId>com.databricks</groupId>
			<artifactId>spark-csv_2.11</artifactId>
			<version>1.4.0</version>
		</dependency>

<!--		<dependency>-->
<!--			<groupId>org.scala-lang</groupId>-->
<!--			<artifactId>scala-library</artifactId>-->
<!--			<version>2.10.1</version>-->
<!--		</dependency>-->

<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-core_2.10</artifactId>-->
<!--			<version>2.0.0</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-sql_2.10</artifactId>-->
<!--			<version>2.0.0</version>-->
<!--		</dependency>-->

<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-core_2.10</artifactId>-->
<!--			<version>1.6.0</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-sql_2.10</artifactId>-->
<!--			<version>1.6.0</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>com.databricks</groupId>-->
<!--			<artifactId>spark-csv_2.10</artifactId>-->
<!--			<version>1.5.0</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>com.univocity</groupId>-->
<!--			<artifactId>univocity-parsers</artifactId>-->
<!--			<version>2.2.3</version>-->
<!--		</dependency>-->

<!--	<dependency>-->
<!--		<groupId>org.apache.spark</groupId>-->
<!--		<artifactId>spark-core_2.12</artifactId>-->
<!--		<version>2.4.5</version>-->
<!--	</dependency>-->
<!--	<dependency>-->
<!--		<groupId>org.apache.spark</groupId>-->
<!--		<artifactId>spark-sql_2.12</artifactId>-->
<!--		<version>2.4.5</version>-->
<!--	</dependency>-->



	<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-core_2.11</artifactId>-->
<!--			<version>2.1.3</version>-->
<!--		</dependency>-->
<!--		<dependency>-->
<!--			<groupId>org.apache.spark</groupId>-->
<!--			<artifactId>spark-sql_2.11</artifactId>-->
<!--			<version>2.1.3</version>-->
<!--		</dependency>-->
	</dependencies>
	<dependencyManagement>
		<dependencies>
			<!--Spark java.lang.NoClassDefFoundError: org/codehaus/janino/InternalCompilerException-->
			<dependency>
				<groupId>org.codehaus.janino</groupId>
				<artifactId>commons-compiler</artifactId>
				<version>3.0.8</version>
			</dependency>
			<dependency>
				<groupId>org.codehaus.janino</groupId>
				<artifactId>janino</artifactId>
				<version>3.0.8</version>
			</dependency>
		</dependencies>
	</dependencyManagement>

	<build>
		<plugins>
			<plugin>
				<groupId>org.springframework.boot</groupId>
				<artifactId>spring-boot-maven-plugin</artifactId>
			</plugin>
		</plugins>
		<finalName>hybrid-db</finalName>
	</build>

	<repositories>
		<repository>
			<id>spring-milestones</id>
			<name>Spring Milestones</name>
			<url>https://repo.spring.io/milestone</url>
		</repository>
	</repositories>
	<pluginRepositories>
		<pluginRepository>
			<id>spring-milestones</id>
			<name>Spring Milestones</name>
			<url>https://repo.spring.io/milestone</url>
		</pluginRepository>
	</pluginRepositories>

</project>